{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgmIRHH1BKUq"
      },
      "source": [
        "### 1.필요한 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ytzvKHiNJxD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqGVqhdkBKUr"
      },
      "source": [
        "### 2.이미지 파일 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 약 3,700장의 꽃 사진 데이터세트를 사용합니다.\n",
        "# 아래 데이터 가져오기 그냥 사용합니다.\n",
        "\n",
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "# 이미지 패스 확인\n",
        "data_dir\n",
        "# 이미지 폴더 밑의 폴더 확인\n",
        "\n",
        "!ls -l /root/.keras/datasets/flower_photos/\n",
        "# daisy 폴더 안의 이지미 갯수\n",
        "!ls -l /root/.keras/datasets/flower_photos/daisy | grep jpg | wc -l\n",
        "# dandelion 폴더 안의 이지미 갯수\n",
        "!ls -l /root/.keras/datasets/flower_photos/dandelion | grep jpg | wc -l\n",
        "# roses 폴더 안의 이지미 갯수\n",
        "!ls -l /root/.keras/datasets/flower_photos/roses | grep jpg | wc -l\n",
        "# sunflowers 폴더 안의 이지미 갯수\n",
        "!ls -l /root/.keras/datasets/flower_photos/sunflowers | grep jpg | wc -l\n",
        "# tulips 폴더 안의 이지미 갯수\n",
        "!ls -l /root/.keras/datasets/flower_photos/tulips | grep jpg | wc -l\n",
        "# 이미지 패스 지정\n",
        "daisy_path = '/root/.keras/datasets/flower_photos/daisy/'\n",
        "dandelion_path = '/root/.keras/datasets/flower_photos/dandelion/'\n",
        "roses_path = '/root/.keras/datasets/flower_photos/roses/'\n",
        "sunflowers_path = '/root/.keras/datasets/flower_photos/sunflowers/'\n",
        "tulips_path = '/root/.keras/datasets/flower_photos/tulips/'\n",
        "# 이미지 패스의 파말 리스트 만들기\n",
        "daisy_file = os.listdir(daisy_path)\n",
        "dandelion_file = os.listdir(dandelion_path)\n",
        "roses_file = os.listdir(roses_path)\n",
        "sunflowers_file = os.listdir(sunflowers_path)\n",
        "tulips_file = os.listdir(tulips_path)\n",
        "# 이미지 파일 리스트 읽어보기\n",
        "daisy_file[:2], roses_file[:2]\n",
        "# Class 라벨 정의\n",
        "\n",
        "class2idx = {'daisy' :  0, 'dandelion' : 1,  'roses' : 2, 'sunflowers' : 3, 'tulips' : 4}\n",
        "idx2class = {0 : 'daisy', 1 : 'dandelion', 2 : 'roses', 3 : 'sunflowers', 4 : 'tulips'}\n",
        "\n",
        "# 수작업으로 이미지 리스트와 라벨 리스트 만들기\n",
        "\n",
        "img_list = []\n",
        "label_list = []\n",
        "\n",
        "daisy_file = os.listdir(daisy_path)\n",
        "for img_file in daisy_file :\n",
        "  img = Image.open(daisy_path + img_file).resize((128,128))\n",
        "  img = np.array(img)/255.  # 이미지 스케일링\n",
        "  img_list.append(img)\n",
        "  label_list.append(0) # daisy : 0\n",
        "\n",
        "dandelion_file = os.listdir(dandelion_path)\n",
        "for img_file in dandelion_file :\n",
        "  img = Image.open(dandelion_path + img_file).resize((128,128))\n",
        "  img = np.array(img)/255.  # 이미지 스케일링\n",
        "  img_list.append(img)\n",
        "  label_list.append(1) # dandelion : 1\n",
        "\n",
        "roses_file = os.listdir(roses_path)\n",
        "for img_file in roses_file :\n",
        "  img = Image.open(roses_path + img_file).resize((128,128))\n",
        "  img = np.array(img)/255.  # 이미지 스케일링\n",
        "  img_list.append(img)\n",
        "  label_list.append(2) # roses : 2\n",
        "\n",
        "sunflowers_file = os.listdir(sunflowers_path)\n",
        "for img_file in sunflowers_file :\n",
        "  img = Image.open(sunflowers_path + img_file).resize((128,128))\n",
        "  img = np.array(img)/255.  # 이미지 스케일링\n",
        "  img_list.append(img)\n",
        "  label_list.append(3) # sunflowers : 2\n",
        "\n",
        "tulips_file = os.listdir(tulips_path)\n",
        "for img_file in tulips_file :\n",
        "  img = Image.open(tulips_path + img_file).resize((128,128))\n",
        "  img = np.array(img)/255.  # 이미지 스케일링\n",
        "  img_list.append(img)\n",
        "  label_list.append(4) # tulips : 2\n",
        "# 이미지 리스트, 라벨 리스트루 numpy array 변경\n",
        "img_list_arr =  np.array(img_list)\n",
        "label_list_arr = np.array(label_list)\n",
        "# 이미지 리스트, 라벨 리스트 shape 확인\n",
        "img_list_arr.shape, label_list_arr.shape\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test , y_train, y_test = train_test_split(img_list_arr, label_list_arr, test_size=0.3, stratify=label_list_arr, random_state=41)\n",
        "X_train.shape, X_test.shape , y_train.shape, y_test.shape\n",
        "# Hyperparameter Tunning\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "learning_rate = 0.001\n",
        "dropout_rate = 0.5\n",
        "\n",
        "input_shape = (128, 128, 3)  # 사이즈 확인\n",
        "# Sequential 모델 정의\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add( Conv2D (32, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
        "model.add( MaxPooling2D (pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Conv2D(64,(2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "# 모델 컴파일\n",
        "model. compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
        "              loss='sparse_categorical_crossentropy',  # Loss Function\n",
        "              metrics=['accuracy'])  # Metrics / Accuracy\n",
        "model.summary()\n",
        "# callback : EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# EarlyStopping\n",
        "es =EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# ModelCheckpoint\n",
        "checkpoint_path = \"my_checkpoint.ckpt\"\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                             save_best_only=True,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1)\n",
        "\n",
        "# num_epochs = 10\n",
        "# batch_size = 32\n",
        "\n",
        "# 모델 학습(fit)\n",
        "history = model.fit (\n",
        "    X_train, y_train ,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=num_epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[es, checkpoint]\n",
        ")\n",
        "history.history.keys()\n",
        "# Test 데이터로 성능 예측하기\n",
        "\n",
        "i=1\n",
        "plt.figure(figsize=(16, 8))\n",
        "for img, label in zip(X_test[:8], y_test[:8]):\n",
        "      # 모델 예측(predict)\n",
        "      pred = model. predict (img.reshape(-1,128, 128, 3))\n",
        "      pred_t = np.argmax(pred)\n",
        "      plt.subplot(2, 4, i)\n",
        "      plt.title(f'True Value:{label}, Pred Value: {pred_t}')\n",
        "      plt.imshow(img)\n",
        "      plt.axis('off')\n",
        "      i = i + 1\n",
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# 약 3,700장의 꽃 사진 데이터세트를 사용합니다.\n",
        "# 아래 데이터 가져오기 그냥 사용합니다.\n",
        "\n",
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "# 이미지 패스 확인\n",
        "data_dir\n",
        "# 이미지 폴더 밑의 폴더 확인\n",
        "\n",
        "!ls -l /root/.keras/datasets/flower_photos/"
      ],
      "metadata": {
        "id": "zmZPE0nbbshP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpq3j-_rJ4wk"
      },
      "source": [
        "###  3. 이미지 파일 하나 읽어 이미지 보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtmdHsveKuIk"
      },
      "outputs": [],
      "source": [
        "# 이미지 패스 지정\n",
        "daisy_path = '/root/.keras/datasets/flower_photos/daisy/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 패스의 파말 리스트 만들기\n",
        "daisy_file = os.listdir(daisy_path)"
      ],
      "metadata": {
        "id": "pyK67lW3KuIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIz-oci2LNlU"
      },
      "outputs": [],
      "source": [
        "# 하이터 파라미터 정의\n",
        "input_shape = (224, 224, 3)\n",
        "batch_size = 32\n",
        "num_classes = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qQrZz3E1Eg2"
      },
      "outputs": [],
      "source": [
        "# 이미지 패스 지정\n",
        "img_path ='/root/.keras/datasets/flower_photos/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi0QpDAd1EeX"
      },
      "outputs": [],
      "source": [
        "# image_dataset_from_directory 함수 활용하여\n",
        "# 이미지 폴더 밑의 이미지들에 대해 원핫인코딩된 labeling수행, 이미지 배치, 셔플 수행\n",
        "\n",
        "# Train Dataset 만들기\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                             directory=img_path,\n",
        "                                             label_mode=\"categorical\",   # binary , categorical\n",
        "                                             batch_size=batch_size,\n",
        "                                             image_size=(224, 224),      # 사이즈 확인\n",
        "                                             seed=42,\n",
        "                                             shuffle=True,\n",
        "                                             validation_split=0.2,\n",
        "                                             subset=\"training\"    # One of \"training\" or \"validation\". Only used if validation_split is set.\n",
        "                                            )\n",
        "\n",
        "# Test Dataset 만들기\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                             directory=img_path,\n",
        "                                             label_mode=\"categorical\",   # binary , categorical\n",
        "                                             batch_size=batch_size,\n",
        "                                             image_size=(224, 224),      # 사이즈 확인\n",
        "                                             seed=42,\n",
        "                                             validation_split=0.2,\n",
        "                                             subset=\"validation\"    # One of \"training\" or \"validation\". Only used if validation_split is set.\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUI7yk4Q8vkU",
        "outputId": "9c2113bb-1023-44a7-8cf1-bb720a4e2517"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Class 이름 확인\n",
        "train_ds.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGVfGgTG1EYi",
        "outputId": "a74306fa-db72-45a9-9894-cf34706262e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2944, 736)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# 40,000건 중에서 32,000건 Train 사용. test용으로 8,000건 사용\n",
        "len(train_ds) * 32 , len(test_ds) * 32"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_img, batch_label = next(iter(train_ds))\n",
        "batch_img.shape, batch_label.shape"
      ],
      "metadata": {
        "id": "v0X-hGI7heTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tunning\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "learning_rate = 0.001\n",
        "dropout_rate = 0.5\n",
        "\n",
        "input_shape = (224, 224, 3)  # 사이즈 확인\n",
        "num_classes = 5\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Rescaling\n",
        "\n",
        "model = Sequential ()\n",
        "model.add( Rescaling (1. / 255))  # 이미지 Rescaling. 없이 하면 성능이 안나옴.\n",
        "model.add( Conv2D (32, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
        "model.add( MaxPooling2D (pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Conv2D(64,(2,2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "# Model compile\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
        "              loss='categorical_crossentropy',  # Loss Function / sparse가 없음\n",
        "              metrics=['accuracy'])  # Metrics / Accuracy\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# EarlyStopping\n",
        "es =EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
        "\n",
        "# ModelCheckpoint\n",
        "checkpoint_path = \"my_checkpoint.ckpt\"\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                             save_best_only=True,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1)\n",
        "# image_dataset_from_directory 이용하여 데이터 만들었을때 아래와 같이 학습 진행\n",
        "# num_epochs = 10\n",
        "\n",
        "# 모델 학습(fit)\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=(test_ds),\n",
        "    epochs=10,\n",
        "    callbacks=[es, checkpoint]\n",
        ")\n",
        "history.history.keys()\n",
        "len(test_ds) * 32\n",
        "# 배치사이즈 이미지/라벨 가져오기\n",
        "batch_img , batch_label = next(iter(test_ds))\n",
        "type(batch_img), batch_img.shape\n",
        "# Test 데이터로 성능 예측하기\n",
        "\n",
        "i = 1\n",
        "plt.figure(figsize=(16, 30))\n",
        "for img, label in list(zip(batch_img, batch_label)):\n",
        "    pred = model.predict(img.numpy().reshape(-1, 224,224,3), verbose=0)\n",
        "    pred_t = np.argmax(pred)\n",
        "    plt.subplot(8, 4, i)\n",
        "    plt.title(f'True Value:{np.argmax(label)}, Pred Value: {pred_t}')\n",
        "    plt.imshow(img/255)  # 이미지 픽셀값들이 실수형이므로 0~1 사이로 변경해야 에러 안남\n",
        "    i = i + 1\n"
      ],
      "metadata": {
        "id": "Jr2mrgZsLXDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnQHExbunT2p"
      },
      "source": [
        "### 1. Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "a18HnMX2nT2p"
      },
      "outputs": [],
      "source": [
        "# 케라스 applicatioins에 어떤 종류의 모델 있는지 확인\n",
        "dir(tf.keras.applications)\n",
        "# 사전 훈련된 모델 MobileNetV2에서 기본 모델을 생성합니다.\n",
        "# 아래와 같은 형식을 MobileNetV2 Transfer Learning 사용하며 됩니다.\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
        "# tf.keras.applications.MobileNetV2 모델은 [-1, 1]의 픽셀 값을 예상하지만 이 시점에서 이미지의 픽셀 값은 [0, 255]입니다.\n",
        "# MobileNetV2 모델에서 제대로 수행하기 위해 크기를 [-1, 1]로 재조정해야 합니다.(안하고 수행해도 성능 잘 나옴)\n",
        "# 방법 2가지 있음\n",
        "# 첫번째 방법 : preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "# 두번째 방법 : rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
        "# MobileNet V2 베이스 모델 고정하기\n",
        "base_model.trainable = False\n",
        "# 모델 구축 : 이미지 픽셀값 조정 수행하기(Rescaling) --> 성능 더 잘 나옴.\n",
        "\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = tf.keras.layers. Rescaling(1./127.5, offset=-1)(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers. GlobalAveragePooling2D()(x)  # 3차원(7, 7, 1280) --> 1차원(1280)으로 줄이기 : GlobalAveragePooling2D\n",
        "output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
        "model.summary()\n",
        "# 모델 compile\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
        "              loss='categorical_crossentropy',  # Loss Function\n",
        "              metrics=['accuracy'])             # Metrics / Accuracy\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
        "\n",
        "# ModelCheckpoint\n",
        "checkpoint_path = \"my_checkpoint.ckpt\"\n",
        "checkpoint = ModelCheckpoint (filepath=checkpoint_path,\n",
        "                             save_best_only=True,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1)\n",
        "# image_dataset_from_directory 이용하여 DataSet을 만들었으며\n",
        "# num_epochs = 10\n",
        "# batch_size = 32\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data = test_ds,\n",
        "    epochs=2,\n",
        "    callbacks=[es, checkpoint]\n",
        ")\n",
        "history.history.keys()\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Model Accuracy')\n",
        "plt.show()\n",
        "# test_generator 샘플 데이터 가져오기\n",
        "# 배치 사이즈 32 확인\n",
        "\n",
        "batch_img, batch_label = next(iter(test_ds))\n",
        "print(batch_img.shape)\n",
        "print(batch_label.shape)\n",
        "# 이미지 rescale 되어 있는 상태\n",
        "batch_img[0][0][:10]\n",
        "# 100% 성능 보여줌\n",
        "\n",
        "i = 1\n",
        "plt.figure(figsize=(16, 30))\n",
        "for img, label in list(zip(batch_img, batch_label)):\n",
        "    pred = model.predict(img.numpy().reshape(-1, 224,224,3), verbose=0)\n",
        "    pred_t = np.argmax(pred)\n",
        "    plt.subplot(8, 4, i)\n",
        "    plt.title(f'True Value:{np.argmax(label)}, Pred Value: {pred_t}')\n",
        "    plt.imshow(img/255)  # 이미지 픽셀값들이 실수형이므로 0~1 사이로 변경해야 에러 안남\n",
        "    i = i + 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}